{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detecting number of components in tissue area and seperating cells based on the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'images\\black_bubbles_3.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the image\n",
    "ret, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of cells: 170\n",
      "num_cell_type1 :52,\n",
      "num_cell_type2 : 53,\n",
      "num_cell_type3 :60\n"
     ]
    }
   ],
   "source": [
    "# find connected components\n",
    "connectivity = 4\n",
    "num_cell_type1 = 0\n",
    "num_cell_type2 = 0\n",
    "num_cell_type3 = 0\n",
    "\n",
    "nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(bw, connectivity, cv2.CV_32S)\n",
    "sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "print(\"# of cells:\",nb_components)\n",
    "min_size = 500 #threshhold value for objects in scene\n",
    "img2 = np.zeros((img.shape), np.uint8)\n",
    "img_label = np.zeros((img.shape[0],img.shape[1],1), np.uint8)\n",
    "\n",
    "for i in range(0, nb_components):\n",
    "    if sizes[i] <= 150: #to identify your objects\n",
    "        color = [255,0,0]\n",
    "        value = 2\n",
    "        num_cell_type2+=1\n",
    "    elif sizes[i] >150 and sizes[i]<350:\n",
    "        color = [0,255,0]\n",
    "        value = 1\n",
    "        num_cell_type1+=1\n",
    "    elif sizes[i] >=350 and sizes[i]<500:\n",
    "        color = [0,0,255]\n",
    "        value = 3\n",
    "        num_cell_type3+=1\n",
    "    else:#background\n",
    "        color = [0,0,0]\n",
    "        value = 0\n",
    "    # draw the bounding rectangele around each object\n",
    "    cv2.rectangle(img2, (stats[i][0],stats[i][1]),(stats[i][0]+stats[i][2],stats[i][1]+stats[i][3]), color, 2)\n",
    "    img2[output == i + 1] = color\n",
    "    img_label[output == i + 1] = value\n",
    "\n",
    "print('num_cell_type1 :%d,\\nnum_cell_type2 : %d,\\nnum_cell_type3 :%d'%(num_cell_type1,num_cell_type2,num_cell_type3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving groundtruth images to train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(\"black_bubbles_3_gt_rec.png\",img2)\n",
    "np.save(\"black_bubbles_3_gt.npy\",img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
